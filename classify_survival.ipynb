{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-10T01:20:39.800340Z","iopub.execute_input":"2023-06-10T01:20:39.800801Z","iopub.status.idle":"2023-06-10T01:20:40.805264Z","shell.execute_reply.started":"2023-06-10T01:20:39.800763Z","shell.execute_reply":"2023-06-10T01:20:40.803822Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/input/merck-datasets/Datasets/acs_housing_5yr.csv\n/kaggle/input/merck-datasets/Datasets/treatments_2017-2020.csv\n/kaggle/input/merck-datasets/Datasets/treatment_facilities_2016_2020.csv\n/kaggle/input/merck-datasets/Datasets/state_county_cbsa_population.csv\n/kaggle/input/merck-datasets/Datasets/acs_demographics_1yr.csv\n/kaggle/input/merck-datasets/Datasets/acs_social_5yr.csv\n/kaggle/input/merck-datasets/Datasets/acs_economics_1yr.csv\n/kaggle/input/merck-datasets/Datasets/acs_demographics_5yr.csv\n/kaggle/input/merck-datasets/Datasets/acs_social_1yr.csv\n/kaggle/input/merck-datasets/Datasets/acs_economics_5yr.csv\n/kaggle/input/merck-datasets/Datasets/acs_housing_1yr.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"path = '/kaggle/input/merck-datasets/Datasets/'","metadata":{"execution":{"iopub.status.busy":"2023-06-10T01:20:43.254636Z","iopub.execute_input":"2023-06-10T01:20:43.255053Z","iopub.status.idle":"2023-06-10T01:20:43.260258Z","shell.execute_reply.started":"2023-06-10T01:20:43.255019Z","shell.execute_reply":"2023-06-10T01:20:43.259009Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"treatments = pd.read_csv(path +'treatments_2017-2020.csv',low_memory=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T01:20:45.638417Z","iopub.execute_input":"2023-06-10T01:20:45.638801Z","iopub.status.idle":"2023-06-10T01:21:56.738067Z","shell.execute_reply.started":"2023-06-10T01:20:45.638769Z","shell.execute_reply":"2023-06-10T01:21:56.736994Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"cleaning: (1) check null? (2) remove -9 appearances in columns studied","metadata":{}},{"cell_type":"code","source":"treatments.isnull().values.any()","metadata":{"execution":{"iopub.status.busy":"2023-06-10T01:21:56.740643Z","iopub.execute_input":"2023-06-10T01:21:56.741451Z","iopub.status.idle":"2023-06-10T01:22:04.712743Z","shell.execute_reply.started":"2023-06-10T01:21:56.741378Z","shell.execute_reply":"2023-06-10T01:22:04.711498Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}]},{"cell_type":"markdown","source":"Preprocessing: prepare a table of dropout studies: <br>\n(1) keep columns interested <br>\n(2) add total num of substances as a new variable (3) LOS - map value,\n(4) REASON map to DROPOUT as Yes or No, remove rows if REASON unknown\n<br>\n(5) survival curve -- keep 365 days or less (6) for regression or classification - convert categorical variables","metadata":{}},{"cell_type":"code","source":"cols = ['REASON', \n        'SUB1', 'ROUTE1', 'FREQ1', 'FRSTUSE1', 'DSMCRIT','FREQ_ATND_SELF_HELP',\n        'DIVISION', 'CBSA',\n        'NOPRIOR', 'AGE', 'GENDER', 'MARSTAT', 'RACE', 'EDUC', 'PREG', 'VET', \n        'LIVARAG', 'ARRESTS', 'PSYPROB',\n        'HLTHINS', 'EMPLOY', 'PRIMPAY',\n        'LOS', 'SERVICES', 'IDU', 'DAYWAIT', 'PSOURCE',\n        'ALCFLG','COKEFLG','MARFLG','HERFLG','METHFLG','OPSYNFLG','PCPFLG',\n        'HALLFLG','MTHAMFLG','AMPHFLG','STIMFLG','BENZFLG','TRNQFLG','BARBFLG',\n        'SEDHPFLG','INHFLG','OTCFLG','OTHERFLG',\n         'METHUSE'\n       ]\n\nlos_convert = {\n    31: 38,\n    32: 53,\n    33: 75.5,\n    34: 105.5,\n    35: 150.5,\n    36: 273\n}","metadata":{"execution":{"iopub.status.busy":"2023-06-10T01:22:26.306140Z","iopub.execute_input":"2023-06-10T01:22:26.306616Z","iopub.status.idle":"2023-06-10T01:22:26.315267Z","shell.execute_reply.started":"2023-06-10T01:22:26.306573Z","shell.execute_reply":"2023-06-10T01:22:26.313981Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def df_prepare(treatments):\n    # note: df name must be changed if rows deleted!\n    \n    treatments1 = treatments[cols]\n    \n    ## add num of total drugs col\n    FLGs = treatments[['ALCFLG','COKEFLG','MARFLG','HERFLG','METHFLG','OPSYNFLG','PCPFLG','HALLFLG','MTHAMFLG','AMPHFLG','STIMFLG','BENZFLG','TRNQFLG','BARBFLG','SEDHPFLG','INHFLG','OTCFLG','OTHERFLG']];\n    total = FLGs.sum(axis=1, numeric_only=True)\n    treatments1['totalSUB'] = total\n    \n    ## map LOS to actual days\n    treatments1['LOS1'] = treatments1['LOS'].replace(los_convert)\n    ## remove REASON unknown rows\n    treatments2 = treatments1[treatments1['REASON'] != 7]\n    ## Attrition col. as dropout YES/NO\n    treatments2['Attrition'] = np.where(treatments2['REASON'] == 2, \"Yes\", \"No\")\n    \n    return treatments2\n\ndef explore(treatments2):\n    \n    treatments_dropout = treatments2[treatments2['REASON'] == 2]\n    #treatments_dropout['LOS1'].describe()\n    treatments_dropout['LOS1'].hist(grid=True, bins=np.arange(0, 370, 10))\n    plt.title('Length of stay for dropout cases')","metadata":{"execution":{"iopub.status.busy":"2023-06-10T01:22:30.200863Z","iopub.execute_input":"2023-06-10T01:22:30.201350Z","iopub.status.idle":"2023-06-10T01:22:30.212442Z","shell.execute_reply.started":"2023-06-10T01:22:30.201308Z","shell.execute_reply":"2023-06-10T01:22:30.211297Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### classification - DROPOUT Yes/No","metadata":{}},{"cell_type":"code","source":"def prepare_balanced_df(treatments2):\n    #keep a number of rows of Non dropout as the same size of dropout rows\n    \n    count_dropout = treatments2[treatments2['Attrition'] == \"Yes\"].shape[0]\n    non_drop = treatments2[treatments2['Attrition'] == \"No\"]\n    cases_drop = treatments2[treatments2['Attrition'] == \"Yes\"]\n    cases_sample_non_drop = non_drop.sample(count_dropout)\n    tr_sample = pd.concat([cases_drop, cases_sample_non_drop], axis=0)\n    \n    return tr_sample","metadata":{"execution":{"iopub.status.busy":"2023-06-10T01:22:37.861344Z","iopub.execute_input":"2023-06-10T01:22:37.861850Z","iopub.status.idle":"2023-06-10T01:22:37.869203Z","shell.execute_reply.started":"2023-06-10T01:22:37.861810Z","shell.execute_reply":"2023-06-10T01:22:37.867802Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# x_cols = [ 'totalSUB',\n# #           'CBSA',\n#           'SUB1', 'ROUTE1', 'FREQ1', 'DSMCRIT','FREQ_ATND_SELF_HELP',\n#          'DIVISION', 'NOPRIOR', 'GENDER',            \n#         'LIVARAG',  'PSYPROB',\n#         'HLTHINS', 'EMPLOY', 'PRIMPAY',\n#         'LOS1', 'SERVICES', 'IDU',  'PSOURCE', \n#           ## low corr.\n# #           'FRSTUSE1', 'MARSTAT','RACE', 'EDUC','PREG', 'VET','ARRESTS',\n# #           'DAYWAIT', 'AGE',\n#          ]\n\nx_cols = [\n    'ROUTE1', 'FREQ1', 'DSMCRIT','FREQ_ATND_SELF_HELP',\n    'DIVISION', 'NOPRIOR', 'GENDER',            \n     'LIVARAG',  'PSYPROB',\n    'HLTHINS', 'EMPLOY', 'PRIMPAY',\n     'LOS1', 'SERVICES', 'IDU',  'PSOURCE',\n    'TRNQFLG', 'INHFLG', 'HERFLG', 'SEDHPFLG', 'BENZFLG', 'OPSYNFLG', \n    'ALCFLG', 'OTCFLG', 'AMPHFLG', 'PCPFLG', 'COKEFLG', 'MTHAMFLG', \n    'MARFLG', 'STIMFLG', 'BARBFLG', 'HALLFLG', 'METHFLG', 'OTHERFLG',\n    'DAYWAIT', 'METHUSE'\n    ]\n\n## categorical - convert to dummies\ncols_convert = [ #'CBSA', 'SUB1',\n                 'ROUTE1', 'FREQ1', 'DSMCRIT','FREQ_ATND_SELF_HELP', \n            'DIVISION', 'NOPRIOR', 'GENDER',\n             'LIVARAG',  'PSYPROB',\n             'HLTHINS', 'EMPLOY', 'PRIMPAY',\n             'SERVICES', 'IDU',  'PSOURCE',\n            'DAYWAIT', 'METHUSE'            \n            ]","metadata":{"execution":{"iopub.status.busy":"2023-06-10T01:22:40.544314Z","iopub.execute_input":"2023-06-10T01:22:40.544795Z","iopub.status.idle":"2023-06-10T01:22:40.553073Z","shell.execute_reply.started":"2023-06-10T01:22:40.544757Z","shell.execute_reply":"2023-06-10T01:22:40.551994Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport lightgbm as lgb\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\n\ndef prep_df_classify(treatments2):\n    \n    ## use all cases\n    tr_clf = treatments2[x_cols +['Attrition']]\n    ## use sampled tr\n    #tr_clf = tr_sample[x_cols +['Attrition']]\n    \n    encoder = LabelEncoder()\n    tr_clf['Attrition1'] = encoder.fit_transform(tr_clf['Attrition'])\n    \n    tr_clf_num = pd.get_dummies(tr_clf, columns=cols_convert) \n## this is the df to use in clf/reg\n\n    ## remove LOS over 365 days cases\n    tr_clf_num = tr_clf_num[tr_clf_num['LOS1'] != 37]\n\n    y_col_clf = ['Attrition1']\n    x_cols_clf = [ x for x in tr_clf_num.columns.tolist() if \"Attrition\" not in x]\n\n    ## remove \"-9\" cols (unknown)\n    x_cols_clf = [ x for x in x_cols_clf if \"_-9\" not in x]\n\n    X = tr_clf_num[x_cols_clf]\n    y = tr_clf_num[y_col_clf]\n    y = y.values.ravel()  # y has to be array\n\n    return X, y\n\ndef classify(X, y):\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n\n    clf = lgb.LGBMClassifier()\n    clf.fit(X_train, y_train)\n    y_pred=clf.predict(X_test)\n\n    accuracy=accuracy_score(y_pred, y_test)\n    print('accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_pred)))\n\n    n_features = len(X_train.columns)\n    feature_importance_pairs = []\n    for i in range(n_features):\n        feature_importance_pairs.append((clf.feature_importances_[i], X_train.columns[i]))\n\n    feature_importance_pairs.sort(reverse=True)\n    print(*feature_importance_pairs, sep=\"\\n\")\n    \n    print(cross_val_score(clf, X, y, cv=5))","metadata":{"execution":{"iopub.status.busy":"2023-06-10T01:22:43.261022Z","iopub.execute_input":"2023-06-10T01:22:43.261484Z","iopub.status.idle":"2023-06-10T01:22:44.843844Z","shell.execute_reply.started":"2023-06-10T01:22:43.261445Z","shell.execute_reply":"2023-06-10T01:22:44.842384Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"## kfold cv\ndef kfoldCV(X, y):\n    \n    N_SPLITS = 5\n    strat_kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=208)\n\n    #scores = np.empty(N_SPLITS)\n\n    for idx, (train_idx, test_idx) in enumerate(strat_kf.split(X, y)):\n        print(\"=\" * 12 + f\"Training fold {idx}\" + 12 * \"=\")\n\n        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n        y_train, y_val = y[train_idx], y[test_idx]\n        eval_set = [(X_val, y_val)]\n\n        lgbm_clf = lgb.LGBMClassifier(n_estimators=100)\n        lgbm_clf.fit(\n            X_train,\n            y_train,\n            eval_set=eval_set,\n            #eval_metric=\"binary_logloss\",\n        )\n\n        preds = lgbm_clf.predict(X_val)  # predict_proba() if use log_loss\n        #loss = log_loss(y_val, preds)\n        print(\"accu. \", accuracy_score(y_val, preds))\n        #scores[idx] = loss\n\n        #print(f\"Fold {idx} finished with logloss score: {loss:.5f} \\n\")\n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-10T01:22:45.660046Z","iopub.execute_input":"2023-06-10T01:22:45.661107Z","iopub.status.idle":"2023-06-10T01:22:45.673016Z","shell.execute_reply.started":"2023-06-10T01:22:45.661057Z","shell.execute_reply":"2023-06-10T01:22:45.671395Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### regression for LOS (act. days not category) ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import r2_score\n\ndef regression(treatments2):\n    ## preprocess: need to take only dropout cases; remove LOS over 365 days\n    \n    tr_clf = treatments2[x_cols +['Attrition']]\n    ## use sampled tr\n    #tr_clf = tr_sample[x_cols +['Attrition']]\n    \n    encoder = LabelEncoder()\n    tr_clf['Attrition1'] = encoder.fit_transform(tr_clf['Attrition'])\n    \n    tr_clf_num = pd.get_dummies(tr_clf, columns=cols_convert) \n\n    ## remove LOS over 365 days cases\n    tr_clf_num = tr_clf_num[tr_clf_num['LOS1'] != 37]\n    tr_reg_num = tr_clf_num[tr_clf_num['Attrition'] == 'Yes']\n    \n    x_cols_clf = [ x for x in tr_clf_num.columns.tolist() if \"Attrition\" not in x]\n    ## remove \"-9\" cols (unknown)\n    x_cols_clf = [ x for x in x_cols_clf if \"_-9\" not in x]\n    x_cols_reg = [ x for x in x_cols_clf if \"LOS\" not in x]\n    y_col_reg = ['LOS1']\n    \n    X = tr_reg_num[x_cols_reg]\n    y = tr_reg_num[y_col_reg]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n    reg = lgb.LGBMRegressor()\n    reg.fit(X_train, y_train)\n    y_pred=reg.predict(X_test)\n\n    print(r2_score(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-06-10T01:23:25.097560Z","iopub.execute_input":"2023-06-10T01:23:25.098045Z","iopub.status.idle":"2023-06-10T01:23:25.110111Z","shell.execute_reply.started":"2023-06-10T01:23:25.098012Z","shell.execute_reply":"2023-06-10T01:23:25.108451Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Survival analysis, T as drop out time","metadata":{}},{"cell_type":"code","source":"!pip install lifelines\nimport lifelines # for survival analysis\nfrom lifelines import KaplanMeierFitter","metadata":{"execution":{"iopub.status.busy":"2023-06-10T01:24:18.545702Z","iopub.execute_input":"2023-06-10T01:24:18.546134Z","iopub.status.idle":"2023-06-10T01:24:39.245147Z","shell.execute_reply.started":"2023-06-10T01:24:18.546092Z","shell.execute_reply":"2023-06-10T01:24:39.243832Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Collecting lifelines\n  Downloading lifelines-0.27.7-py3-none-any.whl (409 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.4/409.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from lifelines) (1.9.3)\nCollecting autograd>=1.5\n  Downloading autograd-1.5-py3-none-any.whl (48 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: matplotlib>=3.0 in /opt/conda/lib/python3.10/site-packages (from lifelines) (3.6.3)\nRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from lifelines) (1.23.5)\nCollecting formulaic>=0.2.2\n  Downloading formulaic-0.6.1-py3-none-any.whl (82 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.3/82.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting autograd-gamma>=0.3\n  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pandas>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from lifelines) (1.5.3)\nRequirement already satisfied: future>=0.15.2 in /opt/conda/lib/python3.10/site-packages (from autograd>=1.5->lifelines) (0.18.3)\nCollecting interface-meta>=1.2.0\n  Downloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\nRequirement already satisfied: wrapt>=1.0 in /opt/conda/lib/python3.10/site-packages (from formulaic>=0.2.2->lifelines) (1.15.0)\nCollecting astor>=0.8\n  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from formulaic>=0.2.2->lifelines) (4.5.0)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines) (9.5.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines) (1.4.4)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines) (2.8.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines) (1.0.7)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines) (4.39.3)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines) (0.11.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines) (21.3)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->lifelines) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.16.0)\nBuilding wheels for collected packages: autograd-gamma\n  Building wheel for autograd-gamma (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4048 sha256=c1279cf98d22442d7a9737538e4473eb2d114d0f371a30f02e9456db74e174cd\n  Stored in directory: /root/.cache/pip/wheels/25/cc/e0/ef2969164144c899fedb22b338f6703e2b9cf46eeebf254991\nSuccessfully built autograd-gamma\nInstalling collected packages: interface-meta, autograd, astor, autograd-gamma, formulaic, lifelines\nSuccessfully installed astor-0.8.1 autograd-1.5 autograd-gamma-0.5.0 formulaic-0.6.1 interface-meta-1.3.0 lifelines-0.27.7\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"def survivalKMF(treatments_comp):\n    \n    # only study <= 365 days cases\n    treatments_comp = treatments_comp[treatments_comp['LOS'] < 37]\n    encoder = LabelEncoder()\n    treatments_comp['Attrition1'] = encoder.fit_transform(treatments_comp['Attrition'])\n    \n    kmf = KaplanMeierFitter()\n    kmf.fit(durations=treatments_comp['LOS1'], event_observed=treatments_comp['Attrition1'])\n\n    kmf.survival_function_.plot(figsize=(8,5))\n    plt.title('Survival Curve estimated with Kaplan-Meier Fitter')\n    plt.xlabel('Length of stay')\n    plt.show()\n\n    kmf.plot_survival_function(figsize=(8,5))\n    plt.title('Survival Curve estimated with Kaplan-Meier Fitter with confidence intervals')\n    plt.xlabel('Length of stay')\n    plt.show()\n\n    kmf.survival_function_","metadata":{"execution":{"iopub.status.busy":"2023-06-10T01:24:39.247200Z","iopub.execute_input":"2023-06-10T01:24:39.247701Z","iopub.status.idle":"2023-06-10T01:24:39.257973Z","shell.execute_reply.started":"2023-06-10T01:24:39.247661Z","shell.execute_reply":"2023-06-10T01:24:39.256620Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:35:32.426288Z","iopub.execute_input":"2023-05-20T16:35:32.426669Z","iopub.status.idle":"2023-05-20T16:35:32.438756Z","shell.execute_reply.started":"2023-05-20T16:35:32.426643Z","shell.execute_reply":"2023-05-20T16:35:32.437710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## main()\n\ndf2 = df_prepare(treatments)\n# X, y = prep_df_classify(df2)\n# classify(X, y)\n# kfoldCV(X, y)\n# regression(df2)\nsurvivalKMF(df2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"accuracy score: 0.7988 -- all cases <br>\n0.7594 -- balanced drop/nondrop","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}